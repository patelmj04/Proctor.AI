{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the necessary dependencies for your projects\n",
    "\n",
    "# pip install opencv-python opencv-contrib-python\n",
    "# pip install opencv-python\n",
    "# pip install dlib\n",
    "# pip install numpy\n",
    "# pip install scipy\n",
    "# pip install imutils\n",
    "# pip install cmake\n",
    "# pip install dlib\n",
    "# pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import time\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting exam proctoring... Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ExamProctor:\n",
    "    def __init__(self):\n",
    "        # Initialize Mediapipe Face Mesh\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        # Thresholds and counters\n",
    "        self.EYE_AR_THRESH = 0.25\n",
    "        self.EYE_AR_CONSEC_FRAMES = 20\n",
    "        self.SUSPICIOUS_MOVEMENT_THRESH = 50\n",
    "        self.counter = 0\n",
    "        self.alerts = []\n",
    "        \n",
    "        # Video capture\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        # Movement tracking\n",
    "        self.prev_position = None\n",
    "        self.suspicious_count = 0\n",
    "\n",
    "    def eye_aspect_ratio(self, eye_landmarks, landmarks, image_shape):\n",
    "        \"\"\"Calculate the eye aspect ratio (EAR) using Mediapipe landmarks\"\"\"\n",
    "        h, w = image_shape[:2]\n",
    "        eye_coords = [(int(landmarks[p].x * w), int(landmarks[p].y * h)) for p in eye_landmarks]\n",
    "        A = dist.euclidean(eye_coords[1], eye_coords[5])\n",
    "        B = dist.euclidean(eye_coords[2], eye_coords[4])\n",
    "        C = dist.euclidean(eye_coords[0], eye_coords[3])\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "\n",
    "    def detect_suspicious_behavior(self, frame):\n",
    "        \"\"\"Detect suspicious behavior including eye movement and head position\"\"\"\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            if len(results.multi_face_landmarks) > 1:\n",
    "                self.alerts.append(f\"[{datetime.now()}] Multiple faces detected\")\n",
    "                cv2.putText(frame, \"MULTIPLE FACES DETECTED!\", (10, 90),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                return frame\n",
    "\n",
    "            # Process single face\n",
    "            face_landmarks = results.multi_face_landmarks[0].landmark\n",
    "            \n",
    "            # Define eye landmark indices (Mediapipe uses different indices than dlib)\n",
    "            LEFT_EYE = [33, 160, 158, 133, 153, 144]  # Approximate left eye points\n",
    "            RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # Approximate right eye points\n",
    "\n",
    "            # Calculate eye aspect ratio\n",
    "            leftEAR = self.eye_aspect_ratio(LEFT_EYE, face_landmarks, frame.shape)\n",
    "            rightEAR = self.eye_aspect_ratio(RIGHT_EYE, face_landmarks, frame.shape)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            if ear < self.EYE_AR_THRESH:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.EYE_AR_CONSEC_FRAMES:\n",
    "                    self.alerts.append(f\"[{datetime.now()}] Potential cheating: Eyes closed\")\n",
    "                    cv2.putText(frame, \"EYES CLOSED!\", (10, 30),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            else:\n",
    "                self.counter = 0\n",
    "\n",
    "            # Head movement detection (using nose tip as reference)\n",
    "            nose_tip = (int(face_landmarks[1].x * frame.shape[1]), int(face_landmarks[1].y * frame.shape[0]))\n",
    "            if self.prev_position is not None:\n",
    "                movement = dist.euclidean(self.prev_position, nose_tip)\n",
    "                if movement > self.SUSPICIOUS_MOVEMENT_THRESH:\n",
    "                    self.suspicious_count += 1\n",
    "                    if self.suspicious_count > 5:\n",
    "                        self.alerts.append(f\"[{datetime.now()}] Suspicious head movement detected\")\n",
    "                        cv2.putText(frame, \"SUSPICIOUS MOVEMENT!\", (10, 60),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    self.suspicious_count = max(0, self.suspicious_count - 1)\n",
    "            self.prev_position = nose_tip\n",
    "\n",
    "            # Draw eye regions (optional visualization)\n",
    "            for idx in LEFT_EYE + RIGHT_EYE:\n",
    "                pt = (int(face_landmarks[idx].x * frame.shape[1]), int(face_landmarks[idx].y * frame.shape[0]))\n",
    "                cv2.circle(frame, pt, 2, (0, 255, 0), -1)\n",
    "\n",
    "        else:\n",
    "            self.alerts.append(f\"[{datetime.now()}] No face detected\")\n",
    "            cv2.putText(frame, \"NO FACE DETECTED!\", (10, 90),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop for proctoring\"\"\"\n",
    "        print(\"Starting exam proctoring... Press 'q' to quit\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture video\")\n",
    "                break\n",
    "\n",
    "            frame = self.detect_suspicious_behavior(frame)\n",
    "\n",
    "            cv2.imshow(\"Exam Proctor\", frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.cleanup()\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources and save alerts\"\"\"\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.face_mesh.close()\n",
    "        \n",
    "        with open(\"proctoring_log.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(self.alerts))\n",
    "        print(\"Proctoring ended. Alerts saved to proctoring_log.txt\")\n",
    "\n",
    "    def __del__(self):\n",
    "        self.cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    proctor = ExamProctor()\n",
    "    try:\n",
    "        proctor.run()\n",
    "    except KeyboardInterrupt:\n",
    "        proctor.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
